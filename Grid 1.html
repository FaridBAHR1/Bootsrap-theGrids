<!doctype html>
<html lang="en" class="h-100">

<head>
    <title>Grid 1</title>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.1/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-F3w7mX95PdgyTmZZMECAngseQB83DfGTowi0iMjiWaeVhAn4FJkqJByhZMI3AhiU" crossorigin="anonymous">

   <link href="css/site.css" rel="stylesheet">
</head>

<body class="d-flex flex-column h-100">

<nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
    <div class="container-fluid">
        <a class="navbar-brand" href="#">Bootstrap & the Grids</a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse"
            aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav me-auto mb-2 mb-md-0">
                <li class="nav-item">
                    <a class="nav-link" href="/index.html">Home</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link active" aria-current="page" href="/Grid 1.html">Grid 1</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/Grid 2.html">Grid 2</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/Grid 3.html">Grid 3</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/Grid 4.html">Grid 4</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/Grid 5.html">Grid 5</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/Grid 6.html">Grid 6</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/Grid 7.html">Grid 7</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/Grid 8.html">Grid 8</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/Grid 9.html">Grid 9</a>
                </li>
            </ul>
        </div>
    </div>
</nav>

    <main class="flex-shrink-0">
       <div class="container">
           <div class="row h-100">
                <div class="col">
                    <div class="bg-secondary text-light h-100 p-3">
                        <h1>COL 1</h1>
                        <h3>Reinforcement Learning</h3>
                        <p>Reinforcement Learning (RL) is a powerful framework for building intelligent agents that can learn to make decisions by interacting with their environment.
                            RL algorithms use trial-and-error learning to discover optimal policies that maximize a reward signal.
                            These algorithms work well in many domains, including robotics, games, and control systems.</p>
                        <h3>Sequential data</h3>
                        <p>However, when it comes to learning from sequential data, such as text or speech, traditional RL algorithms face challenges due to the high-dimensional and sparse nature of the data.
                            This is where Transformers can be useful.
                            Transformers are a type of neural network architecture that has shown significant improvements in natural language processing (NLP) tasks such as language translation, language modeling, and text classification.
                            They are particularly useful for processing sequential data because they can learn long-term dependencies and capture complex patterns in the data.</p> 
                        <h3>Transformers & Reinforcement Learning</h3>
                        <p>One way to combine Transformers and RL is to use the former to preprocess the sequential data and extract useful features that can be used as input to the latter.
                            This approach is called RL with input embeddings, where the embeddings are learned by a Transformer model.
                            Another approach is to use a Transformer model as a critic in an RL framework.
                            The critic is a function that estimates the value of a state or action, and it is used to guide the learning process by providing feedback on the quality of the decisions made by the agent.
                            In this approach, the Transformer model learns to estimate the value of the state or action based on the input sequence, and this value is used as the feedback signal in the RL algorithm.</p>
                    </div>
                </div>
                <div class="col">
                    <div class="bg-dark text-light h-100 p-3">
                        <h1>COL 2</h1>
                        <h3>Reinforcement Learning</h3>
                        <p>Reinforcement Learning (RL) is a powerful framework for building intelligent agents that can learn to make decisions by interacting with their environment.
                            RL algorithms use trial-and-error learning to discover optimal policies that maximize a reward signal.
                            These algorithms work well in many domains, including robotics, games, and control systems.</p>
                        <h3>Sequential data</h3>
                        <p>However, when it comes to learning from sequential data, such as text or speech, traditional RL algorithms face challenges due to the high-dimensional and sparse nature of the data.
                            This is where Transformers can be useful.
                            Transformers are a type of neural network architecture that has shown significant improvements in natural language processing (NLP) tasks such as language translation, language modeling, and text classification.
                            They are particularly useful for processing sequential data because they can learn long-term dependencies and capture complex patterns in the data.</p> 
                        <h3>Transformers & Reinforcement Learning</h3>
                        <p>One way to combine Transformers and RL is to use the former to preprocess the sequential data and extract useful features that can be used as input to the latter.
                            This approach is called RL with input embeddings, where the embeddings are learned by a Transformer model.
                            Another approach is to use a Transformer model as a critic in an RL framework.
                            The critic is a function that estimates the value of a state or action, and it is used to guide the learning process by providing feedback on the quality of the decisions made by the agent.
                            In this approach, the Transformer model learns to estimate the value of the state or action based on the input sequence, and this value is used as the feedback signal in the RL algorithm.</p>
                    </div>
                </div>
           </div>
       </div>
    </main>
    <footer class="footer mt-auto py-3 bg-dark sticky-footer">
        <div class="container-fluid text-center">
            <span class="text-muted">Bootstrap & the Grids 2023</span>
        </div>
    </footer>
    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.1/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-/bQdsTh/da6pkI1MST/rWKFNjaCP5gBSY4sEBT38Q/9RBh9AH40zEOg7Hlq2THRZ" crossorigin="anonymous">
    </script>
</body>

</html>